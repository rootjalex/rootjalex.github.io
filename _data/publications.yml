oopsla2024burrito:
  title: Compilation of Shape Operators on Sparse Arrays
  abstract: "<p>
    We show how to build a compiler for a sparse array language that supports shape operators such as reshaping or
    concatenating arrays, in addition to compute operators. Existing sparse array programming systems implement
    generic shape operators for only some sparse data structures, reduce shape operators on other data structures
    to those, and do not support fusion. Our system compiles sparse array expressions to code that efficiently
    iterates over reshaped views of irregular sparse data structures, without needing to materialize temporary
    storage for intermediates. Our evaluation shows that our approach generates sparse array code competitive with
    popular sparse array libraries: our generated shape operators achieve geometric mean speed-ups of 1.66x-15.3x
    when compared to hand-written kernels in scipy.sparse and 1.67x-651x when compared to generic implementations
    in pydata/sparse. For operators that require data structure conversions in these libraries, our generated code
    achieves geometric mean speed-ups of 7.29x-13.0x when compared to scipy.sparse and 21.3x-511x when compared to
    pydata/sparse. Finally, our evaluation demonstrates that fusing shape and compute operators improves the
    performance of several expressions by geometric mean speed-ups of 1.22x-2.23x.
    </p>"
  venue: "Proceedings of the ACM on Programming Languages, Volume 8, Issue OOPSLA"
  acronym: OOPSLA
  year: 2024
  pdf: /publications/oopsla2024-burrito.pdf
  image:
  code: https://github.com/rootjalex/burrito-artifact
  acmdl: https://doi.org/10.1145/3689752
  month: October
  authors:
    - root
    - yan
    - liu
    - gyurgyik
    - bik
    - kjolstad
  bibtex:

oopsla2024spconv:
  title: Compiler Support for Sparse Tensor Convolutions
  abstract: "<p>
    This paper extends prior work on sparse tensor algebra compilers to generate asymptotically efficient code for
    tensor expressions with affine subscript expressions. Our technique enables compiler support for a wide range
    of sparse computations, including sparse convolutions and pooling that are widely used in ML and graphics
    applications. We propose an approach that gradually rewrites compound subscript expressions to simple subscript
    expressions with loops that exploit the sparsity pattern of the input sparse tensors. As a result, the time
    complexity of the generated kernels is bounded by the number of stored elements and not by the shape of the
    tensors. Our approach seamlessly integrates into existing frameworks and is compatible with recent advances in
    compilers for sparse computations, including the flexibility to efficiently handle arbitrary combinations of
    different sparse tensor formats. The implementation of our algorithm is open source and upstreamed to the MLIR
    sparse compiler. Experimental results show that our method achieves 19.5x speedup when compared with the
    state-of-the-art compiler-based method at 99.9% sparsity. The generated sparse kernels start to outperform dense
    convolution implementations at about 80% sparsity. 
    </p>"
  venue: "Proceedings of the ACM on Programming Languages, Volume 8, Issue OOPSLA"
  acronym: OOPSLA
  year: 2024
  pdf: /publications/oopsla2024-spconv.pdf
  image:
  code: https://hub.docker.com/r/geticliu/sparse_conv_oopsla
  acmdl: https://doi.org/10.1145/3689721
  month: October
  authors:
    - liu
    - root
    - xu
    - li
    - kjolstad
    - bik
  bibtex:

scorch2024:
  title: "Scorch: A Library for Sparse Deep Learning"
  abstract:
  venue: "Under Submission"
  acronym: arXiv
  year: 2024
  pdf: https://arxiv.org/pdf/2405.16883
  preprint: y
  image:
  code:
  acmdl:
  month: May
  authors:
    - yan
    - root
    - gale
    - broman
    - kjolstad
  bibtex:

asplos2023:
  title: Fast Instruction Selection for Fast Digital Signal Processing
  abstract: "<p>
    Modern vector processors support a wide variety of instructions for fixed-point digital
    signal processing. These instructions sup- port a proliferation of rounding, saturating,
    and type conversion modes, and are often fused combinations of more primitive op- erations.
    While these are common idioms in fixed-point signal processing, it is difficult to use
    these operations in portable code. It is challenging for programmers to write down portable
    integer arithmetic in a C-like language that corresponds exactly to one of these instructions,
    and even more challenging for compilers to recognize when these instructions can be used. Our
    system, Pitch- fork, defines a portable fixed-point intermediate representation, FPIR, that
    captures common idioms in fixed-point code. FPIR can be used directly by programmers experienced
    with fixed-point, or Pitchfork can automatically lift from integer operations into FPIR using a
    term-rewriting system (TRS) composed of verified man- ual and automatically-synthesized rules.
    Pitchfork then lowers from FPIR into target-specific fixed-point instructions using a set of
    target-specific TRSs. We show that this approach improves run- time performance of portably-written
    fixed-point signal processing code in Halide, across a range of benchmarks, by geomean 1.31x on x86
    with AVX2, 1.82x on ARM Neon, and 2.44x on Hexagon HVX compared to a standard LLVM-based compiler flow,
    while maintaining or improving existing compile times.
    </p>"
  venue: "International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS)"
  acronym: ASPLOS
  year: 2023
  pdf: /publications/asplos2023-pitchfork.pdf
  image: /assets/pitchfork_arch.png
  code: https://github.com/halide/Halide/tree/rootjalex/trs-codegen
  acmdl: https://doi.org/10.1145/3623278.3624768
  month: March
  authors:
    - root
    - ahmad
    - sharlet
    - adams
    - kamil
    - jrk
  bibtex: "@inproceedings{root2023pitchfork,
          <br>  author = {Root, Alexander J and Ahmad, Maaz Bin Safeer and Sharlet, Dillon and Adams, Andrew and Kamil, Shoaib and Ragan-Kelley, Jonathan},
          <br>  title = {Fast Instruction Selection for Fast Digital Signal Processing},
          <br>  year = {2024},
          <br>  isbn = {9798400703942},
          <br>  publisher = {Association for Computing Machinery},
          <br>  address = {New York, NY, USA},
          <br>  url = {https://doi.org/10.1145/3623278.3624768},
          <br>  doi = {10.1145/3623278.3624768},
          <br>  abstract = {Modern vector processors support a wide variety of instructions for fixed-point digital signal processing. These instructions support a proliferation of rounding, saturating, and type conversion modes, and are often fused combinations of more primitive operations. While these are common idioms in fixed-point signal processing, it is difficult to use these operations in portable code. It is challenging for programmers to write down portable integer arithmetic in a C-like language that corresponds exactly to one of these instructions, and even more challenging for compilers to recognize when these instructions can be used. Our system, Pitchfork, defines a portable fixed-point intermediate representation, FPIR, that captures common idioms in fixed-point code. FPIR can be used directly by programmers experienced with fixed-point, or Pitchfork can automatically lift from integer operations into FPIR using a term-rewriting system (TRS) composed of verified manual and automatically-synthesized rules. Pitchfork then lowers from FPIR into target-specific fixed-point instructions using a set of target-specific TRSs. We show that this approach improves runtime performance of portably-written fixed-point signal processing code in Halide, across a range of benchmarks, by geomean 1.31x on x86 with AVX2, 1.82x on ARM Neon, and 2.44x on Hexagon HVX compared to a standard LLVM-based compiler flow, while maintaining or improving existing compile times.},
          <br>  booktitle = {Proceedings of the 28th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 4},
          <br>  pages = {125-137},
          <br>  numpages = {13},
          <br>  location = {Vancouver, BC, Canada},
          <br>  series = {ASPLOS '23}
          <br>}"

asplos2022:
  title: Vector Instruction Selection for Digital Signal Processors Using Program Synthesis
  abstract: "<p>
    Instruction selection, whereby input code represented in an intermediate representation is
    translated into executable instructions from the target platform, is often the most
    target-dependent component in optimizing compilers. Current approaches include pattern
    matching, which is brittle and tedious to design, or search-based methods, which are
    limited by scalability of the search algorithm. In this paper, we propose a new algorithm
    that first abstracts the target platform instructions into high-level uber-instructions,
    with each uber-instruction unifying multiple concrete instructions from the target platform.
    Program synthesis is used to lift input code sequences into semantically equivalent sequences
    of uber-instructions and then to lower from uber-instructions to machine code. Using 21 real-world
    benchmarks, we show that our synthesis-based instruction selection algorithm can generate instruction
    sequences for a hardware target, with the synthesized code performing up to 2.1x faster as compared
    to code generated by a professionally-developed optimizing compiler for the same platform.
    </p>"
  venue: "International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS)"
  acronym: ASPLOS
  year: 2022
  pdf: /publications/asplos2022-rake.pdf
  image: /assets/rake_arch.png
  code: https://github.com/uwplse/rake
  acmdl: https://dl.acm.org/doi/10.1145/3503222.3507714
  month: March
  authors: 
    - ahmad
    - root_mit
    - adams
    - kamil
    - cheung
  bibtex: "@inproceedings{ahmad2022rake,
          <br>  author = {Ahmad, Maaz Bin Safeer and Root, Alexander J and Adams, Andrew and Kamil, Shoaib and Cheung, Alvin},
          <br>  title = {Vector Instruction Selection for Digital Signal Processors Using Program Synthesis},
          <br>  year = {2022},
          <br>  isbn = {9781450392051},
          <br>  publisher = {Association for Computing Machinery},
          <br>  address = {New York, NY, USA},
          <br>  url = {https://doi.org/10.1145/3503222.3507714},
          <br>  doi = {10.1145/3503222.3507714},
          <br>  abstract = {Instruction selection, whereby input code represented in an intermediate representation is translated into executable instructions from the target platform, is often the most target-dependent component in optimizing compilers. Current approaches include pattern matching, which is brittle and tedious to design, or search-based methods, which are limited by scalability of the search algorithm. In this paper, we propose a new algorithm that first abstracts the target platform instructions into high-level uber-instructions, with each uber-instruction unifying multiple concrete instructions from the target platform. Program synthesis is used to lift input code sequences into semantically equivalent sequences of uber-instructions and then to lower from uber-instructions to machine code. Using 21 real-world benchmarks, we show that our synthesis-based instruction selection algorithm can generate instruction sequences for a hardware target, with the synthesized code performing up to 2.1x faster as compared to code generated by a professionally-developed optimizing compiler for the same platform.},
          <br>  booktitle = {Proceedings of the 27th ACM International Conference on Architectural Support for Programming Languages and Operating Systems},
          <br>  pages = {1004-1016},
          <br>  numpages = {13},
          <br>  keywords = {Instruction selection, program synthesis, compiler optimizations},
          <br>  location = {Lausanne, Switzerland},
          <br>  series = {ASPLOS '22}
          <br>}"
